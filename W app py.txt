import os
import sys
from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template
import json
import logging
from datetime import datetime
import pandas as pd
import csv
import traceback

# Get project root (parent of Python directory)
PROJECT_ROOT = "/Users/robertsteinegger/Desktop/BevaixBot"
ENV_PATH = os.path.join(PROJECT_ROOT, ".env")

print(f"Loading .env from: {ENV_PATH} at {datetime.now().strftime('%H:%M:%S')}")
if os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)
    print(f"✅ .env loaded successfully from {ENV_PATH}")
else:
    print(f"❌ .env file not found at {ENV_PATH}")

# Initialize Flask app
app = Flask(__name__, template_folder='templates', static_folder='static')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# File paths - EXACTLY matching your Swift bot's output locations
DASHBOARD_JSON_PATH = "/Users/robertsteinegger/Desktop/BevaixBot/dashboard.json"
TRADE_LOG_PATH = os.path.join(PROJECT_ROOT, "Output", "trade_log.csv")
ALERTS_CSV_PATH = os.path.join(PROJECT_ROOT, "Output", "alerts.csv")

@app.route('/')
def home():
    return "BevaixBot Flask Server is Running!"

@app.route('/sentiment', methods=['POST'])
def sentiment():
    """Sentiment endpoint for Swift bot"""
    try:
        data = request.get_json()
        pair = data.get('pair', 'BTC-USDT')
        # Return neutral sentiment score
        sentiment_score = 0.1  # Neutral to slightly positive
        return jsonify({"sentiment_score": sentiment_score}), 200
    except Exception as e:
        logger.error(f"Sentiment error: {e}")
        return jsonify({"sentiment_score": 0.0}), 200

@app.route('/new_dashboard')
def new_dashboard():
    return render_template('dashboard.html')

@app.route('/api/new_dashboard')
def api_new_dashboard():
    logger.info(f"🔄 [Python] API called at {datetime.now().strftime('%H:%M:%S')}")
    
    try:
        # 1. READ LIVE DASHBOARD DATA FROM YOUR SWIFT BOT'S EXACT STRUCTURE
        dashboard_data = None
        balances = {"kucoin": 0.0, "bybit": 0.0}
        prices = {}
        connection_status = {}
        
        try:
            if os.path.exists(DASHBOARD_JSON_PATH):
                with open(DASHBOARD_JSON_PATH, 'r') as f:
                    dashboard_data = json.load(f)
                    
                # READ BALANCES - EXACTLY as your Swift code writes them
                balances['kucoin'] = float(dashboard_data.get('kucoinBalance', 0.0))
                balances['bybit'] = float(dashboard_data.get('bybitBalance', 0.0))
                balances['kucoin_futures'] = float(dashboard_data.get('kucoinFuturesBalance', 0.0))
                balances['bybit_futures'] = float(dashboard_data.get('bybitFuturesBalance', 0.0))
                
                # READ LIVE PRICES - EXACTLY as your Swift code writes them in "livePrices"
                live_prices = dashboard_data.get('livePrices', {})
                for pair, pair_prices in live_prices.items():
                    prices[pair] = {
                        "kucoin_spot": float(pair_prices.get('kucoin_spot', 0.0)),
                        "kucoin_futures": float(pair_prices.get('kucoin_futures', 0.0)),
                        "bybit_spot": float(pair_prices.get('bybit_spot', 0.0)),
                        "bybit_futures": float(pair_prices.get('bybit_futures', 0.0))
                    }
                
                # READ CONNECTION STATUS - EXACTLY as your Swift code writes them
                connection_status = dashboard_data.get('connectedExchanges', {})
                
                logger.info(f"✅ [Python] Dashboard data loaded: {len(prices)} pairs with live prices")
                logger.info(f"✅ [Python] Balances: KC=${balances['kucoin']:.2f}, BB=${balances['bybit']:.2f}")
                logger.info(f"✅ [Python] Connections: {connection_status}")
                
        except Exception as e:
            logger.error(f"❌ Dashboard load error: {e}")

        # 2. LOAD REAL TRADES - ENHANCED WITH BETTER CSV PARSING
        trades = []
        try:
            if os.path.exists(TRADE_LOG_PATH):
                # Enhanced CSV parsing to handle malformed lines
                df = pd.read_csv(TRADE_LOG_PATH, on_bad_lines='skip')
                if not df.empty:
                    logger.info(f"📊 [CSV] Read {len(df)} rows from trade log")
                    for index, row in df.tail(20).iterrows():
                        try:
                            # Handle both standard and HFT trade formats
                            trade_data = [
                                str(row.get('timestamp', '')),
                                str(row.get('pair', 'N/A')),
                                str(row.get('exchange', 'N/A')),  # This might be 'strategy' for HFT trades
                                str(row.get('side', 'BUY')),
                                str(row.get('side', 'BUY')),  # Side for display
                                float(row.get('amount', 0.0)),
                                float(row.get('price', 0.0)),
                                float(row.get('profit', 0.0)),
                                float(row.get('fees', 0.0))
                            ]
                            
                            # Validate that we have reasonable data
                            if trade_data[0] and trade_data[1] != 'N/A':
                                trades.append(trade_data)
                            else:
                                logger.warning(f"Skipping invalid trade at row {index}: missing timestamp or pair")
                                
                        except Exception as row_error:
                            logger.warning(f"Skipping malformed trade row {index}: {row_error}")
                            continue
                    
                    logger.info(f"✅ [Python] Loaded {len(trades)} real trades (filtered from CSV)")
                else:
                    logger.info("📊 [CSV] Trade CSV is empty")
            else:
                logger.info("📊 [CSV] No trade CSV found")
        except Exception as e:
            logger.error(f"Trade load error: {e}")
            # Enhanced fallback - try alternative parsing method for malformed CSV
            try:
                logger.info("🔄 [CSV] Attempting alternative CSV parsing...")
                with open(TRADE_LOG_PATH, 'r') as csvfile:
                    csv_reader = csv.reader(csvfile)
                    header = next(csv_reader, None)
                    if header:
                        logger.info(f"📊 [CSV] Header: {header}")
                        for row_num, row in enumerate(csv_reader):
                            try:
                                if len(row) >= 9:  # Minimum required fields
                                    # Map CSV fields to trade data structure
                                    trade_data = [
                                        row[0],  # timestamp
                                        row[2] if len(row) > 2 else 'N/A',  # pair
                                        row[1] if len(row) > 1 else 'N/A',  # exchange/strategy
                                        row[3] if len(row) > 3 else 'BUY',  # side
                                        row[3] if len(row) > 3 else 'BUY',  # side for display
                                        float(row[5]) if len(row) > 5 and row[5].replace('.','').replace('-','').isdigit() else 0.0,  # amount
                                        float(row[4]) if len(row) > 4 and row[4].replace('.','').replace('-','').isdigit() else 0.0,  # price
                                        float(row[6]) if len(row) > 6 and row[6].replace('.','').replace('-','').isdigit() else 0.0,  # profit
                                        float(row[7]) if len(row) > 7 and row[7].replace('.','').replace('-','').isdigit() else 0.0   # fees
                                    ]
                                    trades.append(trade_data)
                                    if len(trades) >= 20:  # Limit to last 20 trades
                                        break
                            except Exception as parse_error:
                                logger.warning(f"Skipping unparseable row {row_num}: {parse_error}")
                                continue
                logger.info(f"✅ [Python] Alternative parsing loaded {len(trades)} trades")
            except Exception as fallback_error:
                logger.error(f"Alternative CSV parsing also failed: {fallback_error}")
                trades = []

        # 3. LOAD REAL ALERTS
        alerts = []
        try:
            if os.path.exists(ALERTS_CSV_PATH):
                with open(ALERTS_CSV_PATH, 'r') as f:
                    csv_reader = csv.reader(f)
                    for row in csv_reader:
                        if len(row) >= 2:
                            alerts.append([row[0], row[1]])
                alerts = alerts[-15:] if alerts else []
                logger.info(f"✅ [Python] Loaded {len(alerts)} real alerts")
        except Exception as e:
            logger.error(f"Alert load error: {e}")

        # 4. CALCULATE METRICS FROM SWIFT DATA OR TRADES
        if dashboard_data:
            # Use metrics calculated by Swift bot
            total_trades = int(dashboard_data.get('totalTrades', len(trades)))
            total_profit = float(dashboard_data.get('totalProfit', 0.0))
            total_fees = float(dashboard_data.get('totalFees', 0.0))
            win_rate = float(dashboard_data.get('winRate', 0.0))
        else:
            # Fallback to calculating from CSV trades
            total_profit = sum(float(trade[7]) for trade in trades) if trades else 0.0
            total_fees = sum(float(trade[8]) for trade in trades) if trades else 0.0
            total_trades = len(trades)
            win_rate = (sum(1 for trade in trades if float(trade[7]) > 0) / total_trades * 100) if total_trades > 0 else 0.0
        
        metrics = {
            "total_profit": total_profit,
            "total_fees": total_fees,
            "total_trades": total_trades,
            "win_rate": win_rate
        }

        # 5. GENERATE PER-PAIR SUMMARY
        per_pair_summary = []
        if trades:
            pair_data = {}
            for trade in trades:
                pair = trade[1]
                profit = float(trade[7])
                fees = float(trade[8])
                
                if pair not in pair_data:
                    pair_data[pair] = {'trades': 0, 'profit': 0.0, 'fees': 0.0, 'wins': 0}
                
                pair_data[pair]['trades'] += 1
                pair_data[pair]['profit'] += profit
                pair_data[pair]['fees'] += fees
                if profit > 0:
                    pair_data[pair]['wins'] += 1
            
            for pair, data in pair_data.items():
                win_rate_pair = (data['wins'] / data['trades'] * 100) if data['trades'] > 0 else 0.0
                per_pair_summary.append({
                    "pair": pair,
                    "trades": data['trades'],
                    "win_rate": win_rate_pair,
                    "profit": data['profit'],
                    "fees": data['fees']
                })

        # 6. CONNECTION ANALYSIS
        active_pairs = [pair for pair in prices.keys() if any(price > 0 for price in prices[pair].values())]
        
        connection_info = {
            "total_pairs": len(prices),
            "active_pairs": len(active_pairs),
            "websocket_status": connection_status,
            "data_timestamp": dashboard_data.get('timestamp', 'no_data') if dashboard_data else 'no_dashboard_file',
            "trading_active": dashboard_data.get('tradingActive', False) if dashboard_data else False
        }

        # 7. BUILD RESPONSE - MATCHING YOUR SWIFT BOT'S DATA STRUCTURE
        response = {
            "timestamp": datetime.now().isoformat(),
            "prices": prices,  # This now contains your exact livePrices structure
            "balances": balances,
            "metrics": metrics,
            "trades": trades,
            "per_pair_summary": per_pair_summary,
            "alerts": alerts,
            "connection_info": connection_info,
            "active_pairs": active_pairs,
            "data_source": "swift_bot_dashboard" if dashboard_data else "csv_files_only"
        }

        # 8. DEBUG LOGGING FOR KUCOIN ISSUE
        kucoin_pairs = [pair for pair in prices.keys() if prices[pair]['kucoin_spot'] > 0 or prices[pair]['kucoin_futures'] > 0]
        bybit_pairs = [pair for pair in prices.keys() if prices[pair]['bybit_spot'] > 0 or prices[pair]['bybit_futures'] > 0]
        
        logger.info(f"🔍 [DEBUG] KuCoin pairs with prices: {len(kucoin_pairs)} - {kucoin_pairs[:5]}")
        logger.info(f"🔍 [DEBUG] Bybit pairs with prices: {len(bybit_pairs)} - {bybit_pairs[:5]}")
        logger.info(f"🔍 [DEBUG] KuCoin connection status: {connection_status.get('kucoin', False)}")
        logger.info(f"🔍 [DEBUG] Bybit connection status: {connection_status.get('bybit', False)}")

        logger.info(f"✅ [Python] API SUCCESS: {total_trades} trades, {len(alerts)} alerts, {len(active_pairs)} active pairs")
        return jsonify(response), 200

    except Exception as e:
        logger.error(f"❌ [Python] API ERROR: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        return jsonify({
            "error": f"Server error: {str(e)}",
            "timestamp": datetime.now().isoformat(),
            "prices": {},
            "balances": {"kucoin": 0.0, "bybit": 0.0},
            "metrics": {"total_profit": 0.0, "total_fees": 0.0, "total_trades": 0, "win_rate": 0.0},
            "trades": [],
            "per_pair_summary": [],
            "alerts": [],
            "connection_info": {"total_pairs": 0, "active_pairs": 0, "websocket_status": {}}
        }), 200

@app.route('/debug/status')
def debug_status():
    """Debug endpoint"""
    dashboard_data = None
    try:
        if os.path.exists(DASHBOARD_JSON_PATH):
            with open(DASHBOARD_JSON_PATH, 'r') as f:
                dashboard_data = json.load(f)
    except:
        pass
    
    status = {
        "server_time": datetime.now().isoformat(),
        "current_dir": os.getcwd(),
        "files": {
            "trade_log_exists": os.path.exists(TRADE_LOG_PATH),
            "alerts_csv_exists": os.path.exists(ALERTS_CSV_PATH),
            "dashboard_json_exists": os.path.exists(DASHBOARD_JSON_PATH),
            "env_file_exists": os.path.exists(ENV_PATH)
        },
        "dashboard_summary": {
            "has_data": dashboard_data is not None,
            "timestamp": dashboard_data.get('timestamp') if dashboard_data else None,
            "live_pairs_count": len(dashboard_data.get('livePrices', {})) if dashboard_data else 0,
            "connections": dashboard_data.get('connectedExchanges') if dashboard_data else None
        } if dashboard_data else {"has_data": False},
        "routes": [rule.rule for rule in app.url_map.iter_rules()]
    }
    return jsonify(status)

@app.route('/debug/dashboard')
def debug_dashboard():
    """Show raw dashboard JSON for debugging"""
    try:
        if os.path.exists(DASHBOARD_JSON_PATH):
            with open(DASHBOARD_JSON_PATH, 'r') as f:
                data = json.load(f)
            return f"<pre>{json.dumps(data, indent=2)}</pre>"
        else:
            return f"<pre>Dashboard file not found at: {DASHBOARD_JSON_PATH}</pre>"
    except Exception as e:
        return f"<pre>Error reading dashboard: {str(e)}</pre>"

if __name__ == '__main__':
    logger.info(f"🚀 [Python] Starting Flask Server at {datetime.now().strftime('%H:%M:%S')}")
    logger.info(f"📁 [Python] Project root: {PROJECT_ROOT}")
    logger.info(f"📄 [Python] Dashboard path: {DASHBOARD_JSON_PATH}")
    logger.info("📍 Routes available:")
    logger.info("   http://127.0.0.1:5001/new_dashboard")
    logger.info("   http://127.0.0.1:5001/api/new_dashboard")
    logger.info("   http://127.0.0.1:5001/debug/status")
    logger.info("   http://127.0.0.1:5001/debug/dashboard (Raw JSON)")
    
    app.run(host='127.0.0.1', port=5001, debug=True)
